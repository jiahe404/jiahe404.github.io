<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>HeBlog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-05-27T10:12:18.270Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Parker</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>优雅地更改hexo主题</title>
    <link href="http://yoursite.com/1054489955.html"/>
    <id>http://yoursite.com/1054489955.html</id>
    <published>2019-05-26T06:49:05.000Z</published>
    <updated>2019-05-27T10:12:18.270Z</updated>
    
    <content type="html"><![CDATA[<p>本文延续《利用GitHub项目主页实现多个独立博客》，讲下更新默认主题的一些问题。</p><p>我自己的技术博客采用nexT主题，不过给老爸放诗歌这个主题就不太适合了，看了下<a href="https://hexo.io/themes/" target="_blank" rel="noopener">官网主题列表</a>，最终选择了<a href="https://blog.zhangruipeng.me/hexo-theme-hueman/" target="_blank" rel="noopener">hueman</a>这款。主要考虑到这个主题的布局、文章缩略图、画廊功能，很适合写日记。<br><a id="more"></a><br><a href="https://github.com/ppoffice/hexo-theme-hueman" target="_blank" rel="noopener">hueman github链接</a></p><h1 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h1><h2 id="1-下载主题并配置"><a href="#1-下载主题并配置" class="headerlink" title="1. 下载主题并配置:"></a>1. 下载主题并配置:</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd your/blog/dir</span><br><span class="line"><span class="meta">#</span> 错误的做法，先不要这么干！</span><br><span class="line">git clone https://github.com/ppoffice/hexo-theme-hueman.git themes/hueman</span><br><span class="line">mv themes/hueman/_config.yml.example themes/hueman/_config.yml</span><br><span class="line">vi _config.yml</span><br><span class="line"><span class="meta">#</span> 将站点根目录下的_config.yml(非themes/hueman/_config.yml)中theme更改为hueman</span><br><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo s -p 8008</span><br></pre></td></tr></table></figure><h2 id="2-打开浏览器，不一样的hueman"><a href="#2-打开浏览器，不一样的hueman" class="headerlink" title="2. 打开浏览器，不一样的hueman:"></a>2. 打开浏览器，不一样的hueman:</h2><p><img src="/img/blog/change-hexo-theme/hueman.png" alt="hueman主题"></p><h1 id="保存markdown文档到hexo分支"><a href="#保存markdown文档到hexo分支" class="headerlink" title="保存markdown文档到hexo分支"></a>保存markdown文档到hexo分支</h1><p>做到这里，我想按照<a href="https://jiahe404.github.io/3974204864.html" target="_blank" rel="noopener">《在多台电脑上写GitHub Pages博客》</a>方法，将markdown文档、图片等保存到repo的hexo分支上，但却出现了一些问题。</p><h2 id="1-初始化仓库"><a href="#1-初始化仓库" class="headerlink" title="1. 初始化仓库"></a>1. 初始化仓库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd your/blog/dir</span><br><span class="line"><span class="meta">#</span> 将当前目录初始为git仓库</span><br><span class="line">git init</span><br><span class="line"><span class="meta">#</span> 添加远端仓库</span><br><span class="line">git remote add origin git@github.com:jiahe404/demo.git</span><br><span class="line"><span class="meta">#</span> 建立本地分支hexo</span><br><span class="line">git checkout -b hexo</span><br></pre></td></tr></table></figure><h2 id="2-添加文件时报错"><a href="#2-添加文件时报错" class="headerlink" title="2. 添加文件时报错"></a>2. 添加文件时报错</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">git add ./</span><br><span class="line"></span><br><span class="line">output:</span><br><span class="line">Changes not staged for commit:</span><br><span class="line">  (use "git add &lt;file&gt;..." to update what will be committed)</span><br><span class="line">  (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)</span><br><span class="line">  (commit or discard the untracked or modified content in submodules)</span><br><span class="line"></span><br><span class="line">        modified:   themes/hueman (modified content)</span><br></pre></td></tr></table></figure><p>提示说themes/hueman是一个子git仓库模块，并且里面有更改。</p><p>原因是我在上面运行过:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv themes/hueman/_config.yml.example themes/hueman/_config.yml</span><br></pre></td></tr></table></figure></p><p>我的博客是一个git仓库，而里面用到的theme也是一个独立的git仓库，这就会引发一些冲突。如何优雅地处理这个问题呢，自然想到用git submodule。</p><blockquote><p>这里面最粗暴的解决方法，就是将themes/hueman/.git等目录文件删掉，将其作为普通文件由博客的git仓库统一管理，不过后续再想更新这个主题就麻烦了。我之前应该就是这样做的，这次不想用这种ugly方式了。</p></blockquote><p>如果现在用 git submodule 命令会提示错误(所以如果不处理这个问题，将无法使用git submodule):<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git submodule</span><br><span class="line"><span class="meta">#</span> output:</span><br><span class="line"><span class="meta">#</span> fatal: no submodule mapping found in .gitmodules for path 'themes/hueman'</span><br></pre></td></tr></table></figure></p><h2 id="3-正确的做法"><a href="#3-正确的做法" class="headerlink" title="3. 正确的做法"></a>3. 正确的做法</h2><ol><li><p>彻底删掉git clone过来的主题仓库，见<a href="https://gist.github.com/myusuf3/7f645819ded92bda6677" target="_blank" rel="noopener">delete submodule</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git rm --cached themes/hueman -f</span><br><span class="line">vi .gitmodules</span><br><span class="line"><span class="meta">#</span> 删掉对应代码块</span><br><span class="line">vi .git/config</span><br><span class="line"><span class="meta">#</span> 删掉对应代码块</span><br></pre></td></tr></table></figure></li><li><p>利用git submodule添加主题</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git submodule add https://github.com/ppoffice/hexo-theme-hueman.git themes/hueman</span><br><span class="line">git submodule</span><br><span class="line"><span class="meta">#</span> output显示正确子模块信息:</span><br><span class="line"><span class="meta">#</span> 5bf00fd62e5c79c430553bde4142dbde314ab3db themes/hueman (v0.4.0-20-g5bf00fd)</span><br><span class="line">mv themes/hueman/_config.yml.example themes/hueman/_config.yml</span><br></pre></td></tr></table></figure></li><li><p>将theme目录下_config.yml加入代码库(换了台电脑还是需要这个文件的)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd themes/hueman/</span><br><span class="line">vi _config.yml</span><br><span class="line"><span class="meta">#</span> 删掉_config.yml</span><br><span class="line">git add ./</span><br><span class="line">git commit -m "Save _config.yml for hueman theme."</span><br><span class="line">cd -</span><br><span class="line"><span class="meta">#</span> 在submodule目录中commit后，回到外层仓库仍需要add、commit</span><br><span class="line">git add themes/hueman</span><br><span class="line">git commit -m "Modify hueman config."</span><br><span class="line">git push origin hexo</span><br></pre></td></tr></table></figure></li></ol><p>之前急于搭建一个博客，没有关注恰当的方法，现在补上，同时复习下git submodule相关命令，感觉一切都回到了正轨。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文延续《利用GitHub项目主页实现多个独立博客》，讲下更新默认主题的一些问题。&lt;/p&gt;
&lt;p&gt;我自己的技术博客采用nexT主题，不过给老爸放诗歌这个主题就不太适合了，看了下&lt;a href=&quot;https://hexo.io/themes/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官网主题列表&lt;/a&gt;，最终选择了&lt;a href=&quot;https://blog.zhangruipeng.me/hexo-theme-hueman/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;hueman&lt;/a&gt;这款。主要考虑到这个主题的布局、文章缩略图、画廊功能，很适合写日记。&lt;br&gt;
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="GitHub Pages" scheme="http://yoursite.com/tags/GitHub-Pages/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
      <category term="git submodule" scheme="http://yoursite.com/tags/git-submodule/"/>
    
  </entry>
  
  <entry>
    <title>利用GitHub项目主页实现多个独立博客</title>
    <link href="http://yoursite.com/2225712446.html"/>
    <id>http://yoursite.com/2225712446.html</id>
    <published>2019-05-24T16:00:00.000Z</published>
    <updated>2019-05-27T10:12:35.721Z</updated>
    
    <content type="html"><![CDATA[<p>之前用github page给自己搭建了一个技术博客，年后想给老爸也搞个博客，记录下他的诗歌，作为生日礼物。</p><p>现将这个摸索的过程记下。</p><p>首先明确下，一个github账户是可以实现管理多个独立博客的。这主要是利用了“项目主页”。<br><a id="more"></a></p><h1 id="个人-组织主页和项目主页的区别"><a href="#个人-组织主页和项目主页的区别" class="headerlink" title="个人/组织主页和项目主页的区别"></a>个人/组织主页和项目主页的区别</h1><p>区别见: <a href="https://help.github.com/en/articles/user-organization-and-project-pages" target="_blank" rel="noopener">https://help.github.com/en/articles/user-organization-and-project-pages</a></p><p>总结一下，github的目的是，个人/组织主页用于展示个人/组织的整体情况(于个人来讲可能是技术博客等)，而项目主页用于展示前者提到的细节、实现等(比如某一篇博客中实验的全部代码、数据集等不适合放在博客中的内容)。</p><p>前者的访问链接: &lt;username/orgname&gt;.github.io<br>后者的访问链接: &lt;username/orgname&gt;.github.io/projectname  </p><p>在项目主页的目录下，同样利用hexo搭建一个博客，就可以实现多个独立的博客了，只不过链接后缀多了个名字，也可以用于区分博客，无伤大雅。</p><h1 id="创建项目主页repository"><a href="#创建项目主页repository" class="headerlink" title="创建项目主页repository"></a>创建项目主页repository</h1><blockquote><p>由于github页面也会更新升级，所以你看到的页面可能和下面的图片不太一样，不过大体上应该是相同的(本篇博客写于2019-05-25)。</p></blockquote><h2 id="1-创建新repository"><a href="#1-创建新repository" class="headerlink" title="1. 创建新repository"></a>1. 创建新repository</h2><ol><li><p>点击 <strong>new repository</strong><br><img src="/img/blog/problems-with-project-pages/create_new_repo.png" alt="点击 new repository"></p></li><li><p>输入repository名，点击 <strong>create reposityory</strong>，这里将repo命名为demo<br><img src="/img/blog/problems-with-project-pages/input-repo-name.png" alt="点击 create reposityory"></p></li></ol><h2 id="2-更改repository为github-Pages"><a href="#2-更改repository为github-Pages" class="headerlink" title="2. 更改repository为github Pages"></a>2. 更改repository为github Pages</h2><ol><li><p>点击 <strong>setting</strong><br><img src="/img/blog/problems-with-project-pages/setting.png" alt="点击 setting"></p></li><li><p>下拉找到 <strong>GitHub Pages选项卡</strong><br><img src="/img/blog/problems-with-project-pages/hint-for-add-content.png" alt="点击 GitHub Pages选项卡"><br>我们找GitHub Pages选项卡，是因为需要将这个普通repo转换成github pages才能实现博客功能。<br>红框中提示我们目前github page是禁用的，需要先添加一个内容到repo，才能将此项目作为github pages站点(也就是博客)使用。</p><blockquote><p>之前版本的github是没有这步的，黄框中内容都可以直接选择，但是当前版本是置灰无法选择的。</p></blockquote></li><li><p>新建文件<br><img src="/img/blog/problems-with-project-pages/create-new-file.png" alt="新建文件"></p></li><li><p>写入内容<br><img src="/img/blog/problems-with-project-pages/hello.png" alt="写入内容"><br>页面拉到最下方输入commit信息提交。</p></li><li><p>重新找到 <strong>GitHub Pages选项卡</strong>，红框中内容已改变<br><img src="/img/blog/problems-with-project-pages/select-source.png" alt="选择数据源"></p></li><li><p>点击 <strong>master branch</strong>，页面稍后自动刷新，红框中提示站点已经发布<br><img src="/img/blog/problems-with-project-pages/refresh.png" alt="选择数据源"></p></li><li><p>访问 <a href="https://jiahe404.github.io/demo/hello.html，显示内容！" target="_blank" rel="noopener">https://jiahe404.github.io/demo/hello.html，显示内容！</a><br><img src="/img/blog/problems-with-project-pages/access-page.png" alt="选择数据源"></p><blockquote><p>这一步通常要过一段时间才能生效，如果提示404，建议换个浏览器或稍等一段时间再试。</p></blockquote></li></ol><p>至此我们已经成功创建了一个项目主页，接下来结合hexo将此项目主页转化为一个博客！</p><h1 id="搭建hexo博客"><a href="#搭建hexo博客" class="headerlink" title="搭建hexo博客"></a>搭建hexo博客</h1><p>利用项目主页搭建博客，与个人主页相比是类似的，跳过环境问题。</p><h2 id="1-在本地初始化hexo博客"><a href="#1-在本地初始化hexo博客" class="headerlink" title="1. 在本地初始化hexo博客"></a>1. 在本地初始化hexo博客</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd your/blog/dir</span><br><span class="line">hexo init</span><br><span class="line">hexo g</span><br><span class="line">hexo s -p 8008</span><br></pre></td></tr></table></figure><p>浏览器中看到熟悉的默认landscape主题首页:<br><img src="/img/blog/problems-with-project-pages/landscape.png" alt="landscape"></p><h2 id="2-发布到github项目主页"><a href="#2-发布到github项目主页" class="headerlink" title="2. 发布到github项目主页"></a>2. 发布到github项目主页</h2><ol><li>更改站点目录下(非theme目录)_config.yml，重点！  <blockquote><p>注意！<strong>由于使用了项目主页，链接后缀需要加上项目名称，所以url和root的配置中也要加入项目名称，本例中为demo</strong>；而deploy中的配置项，则和个人主页一致</p></blockquote></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># vim _config.yml</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">url: http://yoursite.com/demo</span><br><span class="line">root: /demo</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/jiahe404/demo.git</span><br><span class="line">  branch: master</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><ol start="2"><li>发布</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>稍等几分钟后访问: <a href="https://jiahe404.github.io/demo/，" target="_blank" rel="noopener">https://jiahe404.github.io/demo/，</a> 同样熟悉的landscape：<br><img src="/img/blog/problems-with-project-pages/landscape2.png" alt="landscape"></p><p>注意到目前为止<strong>我并没有创建其他分支，如gh-pages等</strong>，一些博客资料上写个人主页只能发布master分支内容(应该是正确的)，而项目主页只能发布gh-pages分支内容(我在<a href="https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages" target="_blank" rel="noopener">官方文档</a>上并未找到依据)。</p><p>下面是官方文档的说明，只支持前半句：</p><blockquote><p>If your site is a User or Organization Page that has a repository named <username>.github.ioor <orgname>.github.io, you cannot publish your site’s source files from different locations. User and Organization Pages that have this type of repository name are only published from the master branch.</orgname></username></p></blockquote><p>接下来就可以开始搞第3个博客了！</p><p>接下来就可以开始搞第4个博客了！</p><p>接下来就可以开始搞第N个博客了！</p><p>没错，项目主页可以创建多个，而个人主页只能有一个，这也是二者的区别之一。</p><p>下一篇文章打算延续这个demo，写下更改主题的细节。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前用github page给自己搭建了一个技术博客，年后想给老爸也搞个博客，记录下他的诗歌，作为生日礼物。&lt;/p&gt;
&lt;p&gt;现将这个摸索的过程记下。&lt;/p&gt;
&lt;p&gt;首先明确下，一个github账户是可以实现管理多个独立博客的。这主要是利用了“项目主页”。&lt;br&gt;
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="GitHub Pages" scheme="http://yoursite.com/tags/GitHub-Pages/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>python数据分析之dataframe VS sql</title>
    <link href="http://yoursite.com/4015900360.html"/>
    <id>http://yoursite.com/4015900360.html</id>
    <published>2018-11-21T16:00:00.000Z</published>
    <updated>2019-03-27T08:44:58.525Z</updated>
    
    <content type="html"><![CDATA[<p>在分析数据时，dataframe的很多方法和sql是类似的，本文总结一些二者中的相通问题，方便互相转移，下面以mysql语法为例。<br><a id="more"></a></p><h1 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h1><p>为了同时使用sql和dataframe进行分析，分别准备数据库和文本文件(下面的sql和python代码都可以直接运行)。</p><h2 id="1-mysql表"><a href="#1-mysql表" class="headerlink" title="1. mysql表"></a>1. mysql表</h2><p>假如有一个table，包含一些影视音乐作品，数据分4列，分别为一、二级分类，作品名，评分:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> multi_category_data (</span><br><span class="line">    cat1 <span class="built_in">varchar</span>(<span class="number">8</span>),</span><br><span class="line">    cat2 <span class="built_in">varchar</span>(<span class="number">8</span>),</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">8</span>),</span><br><span class="line">    score <span class="built_in">int</span></span><br><span class="line">)<span class="keyword">engine</span>=myisam <span class="keyword">default</span> <span class="keyword">charset</span>=utf8;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'影视'</span>, <span class="string">'电影'</span>, <span class="string">'a'</span>, <span class="number">5</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'影视'</span>, <span class="string">'连续剧'</span>, <span class="string">'b'</span>, <span class="number">6</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'影视'</span>, <span class="string">'连续剧'</span>, <span class="string">'c'</span>, <span class="number">7</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'音乐'</span>, <span class="string">'流行'</span>, <span class="string">'d'</span>, <span class="number">10</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'音乐'</span>, <span class="string">'流行'</span>, <span class="string">'e'</span>, <span class="number">8</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'音乐'</span>, <span class="string">'民谣'</span>, <span class="string">'f'</span>, <span class="number">9</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'音乐'</span>, <span class="string">'摇滚'</span>, <span class="string">'g'</span>, <span class="number">4</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> multi_category_data <span class="keyword">values</span>(<span class="string">'音乐'</span>, <span class="string">'摇滚'</span>, <span class="string">'h'</span>, <span class="number">4</span>);</span><br></pre></td></tr></table></figure><h2 id="2-文本文件"><a href="#2-文本文件" class="headerlink" title="2. 文本文件"></a>2. 文本文件</h2><p>为了用dataframe分析，将同样的数据保存在csv_file文件中，并以dataframe格式保存到变量data:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">multi_category_data = <span class="string">"""</span></span><br><span class="line"><span class="string">cat1,cat2,name,score</span></span><br><span class="line"><span class="string">影视,电影,a,5</span></span><br><span class="line"><span class="string">影视,连续剧,b,6</span></span><br><span class="line"><span class="string">影视,连续剧,c,7</span></span><br><span class="line"><span class="string">音乐,流行,d,10</span></span><br><span class="line"><span class="string">音乐,流行,e,8</span></span><br><span class="line"><span class="string">音乐,民谣,f,9</span></span><br><span class="line"><span class="string">音乐,摇滚,g,4</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">csv_file = io.StringIO(multi_category_data)</span><br><span class="line">data = pd.read_csv(csv_file, sep=<span class="string">','</span>, names=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure></p><h1 id="分析实战"><a href="#分析实战" class="headerlink" title="分析实战"></a>分析实战</h1><h2 id="1-去重问题-——-drop-duplicates-VS-distinct"><a href="#1-去重问题-——-drop-duplicates-VS-distinct" class="headerlink" title="1. 去重问题 —— drop_duplicates() VS distinct"></a>1. 去重问题 —— drop_duplicates() VS distinct</h2><p>drop_duplicates()方法可以对数据按列名去重，类似于sql中的distinct。  </p><p>现在我想了解作品都有哪些一、二级分类，可以如下实现:</p><ul><li><p>linux sort(一句话的事，但不是本文的重点)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sort -t , -k1,1 multi_category_data</span><br></pre></td></tr></table></figure></li><li><p>sql</p></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    <span class="keyword">distinct</span> cat1, cat2</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    multi_category_data;</span><br><span class="line"># 或</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    cat1, cat2</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    multi_category_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    cat1, cat2;</span><br></pre></td></tr></table></figure><ul><li>dataframe<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data[[<span class="string">'cat1'</span>, <span class="string">'cat2'</span>]].drop_duplicates()</span><br><span class="line"><span class="comment"># data[['cat1', 'cat2']].drop_duplicates(keep='first')</span></span><br><span class="line"><span class="comment"># data[['cat1', 'cat2']].drop_duplicates(keep='last')</span></span><br></pre></td></tr></table></figure></li></ul><p>输出:<br><img src="/img/blog/df/distinct1.png" alt></p><p>drop_duplicates的参数keep指定在数据重复时保留首行或末行，可以通过第1列行号来区别保留的哪一行，如默认保留首行，所以我们看到有重复行的[影视,连续剧]、[音乐,流行]前的行号分别为1和3，对应原始数据其首次出现的行号。</p><h2 id="2-分组问题"><a href="#2-分组问题" class="headerlink" title="2. 分组问题"></a>2. 分组问题</h2><h3 id="1-对单列或多列执行相同的聚合操作"><a href="#1-对单列或多列执行相同的聚合操作" class="headerlink" title="1. 对单列或多列执行相同的聚合操作"></a>1. 对单列或多列执行相同的聚合操作</h3><p>比如想看看各个二级类目下都有多少作品:</p><ul><li><p>sql</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    cat1, cat2, <span class="keyword">count</span>(<span class="keyword">name</span>)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    multi_category_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    cat1, cat2</span><br></pre></td></tr></table></figure></li><li><p>dataframe</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>])[[<span class="string">'name'</span>]].count()</span><br></pre></td></tr></table></figure></li></ul><p>输出:<br><img src="/img/blog/df/group1.png" alt></p><p>更多例子:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>])[[<span class="string">'score'</span>]].max()</span><br><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>])[[<span class="string">'score'</span>]].min()</span><br><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>])[[<span class="string">'score'</span>]].mean()</span><br><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>])[[<span class="string">'score'</span>]].sum()</span><br><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>])[[<span class="string">'name'</span>, <span class="string">'score'</span>]].max()</span><br></pre></td></tr></table></figure></p><h3 id="2-对多列分别执行不同的聚合操作"><a href="#2-对多列分别执行不同的聚合操作" class="headerlink" title="2. 对多列分别执行不同的聚合操作"></a>2. 对多列分别执行不同的聚合操作</h3><p>比如想看看所有二级分类下作品分值情况，如平均值、极值等，这里主要借助numpy的内置方法:</p><ul><li><p>sql</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    cat1, cat2,</span><br><span class="line">    <span class="keyword">count</span>(<span class="keyword">name</span>), <span class="keyword">avg</span>(score), <span class="keyword">sum</span>(score), <span class="keyword">min</span>(score), <span class="keyword">max</span>(score)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    multi_category_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    cat1, cat2</span><br></pre></td></tr></table></figure></li><li><p>dataframe</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>]).agg(&#123;<span class="string">'name'</span>: [np.size], <span class="string">'score'</span>: [np.mean, np.sum, np.min, np.max]&#125;)</span><br></pre></td></tr></table></figure></li></ul><p>输出:<br><img src="/img/blog/df/group2.png" alt></p><h3 id="3-自定义聚合方法"><a href="#3-自定义聚合方法" class="headerlink" title="3. 自定义聚合方法"></a>3. 自定义聚合方法</h3><p>如何实现count(distinct column)操作呢？可以仿照numpy中内置的聚合方法，自定义一个:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_distinct</span><span class="params">(rows)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(set(e <span class="keyword">for</span> e <span class="keyword">in</span> rows))</span><br><span class="line"></span><br><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>]).agg(&#123;<span class="string">'name'</span>: [np.size], <span class="string">'score'</span>: [np.mean, np.sum, np.min, np.max, my_distinct]&#125;)</span><br></pre></td></tr></table></figure></p><p>也可以采用lamba表达式实现匿名函数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>]).agg(&#123;<span class="string">'name'</span>: [np.size], <span class="string">'score'</span>: [np.mean, np.sum, np.min, np.max, <span class="keyword">lambda</span> rows: len(set(e <span class="keyword">for</span> e <span class="keyword">in</span> rows))]&#125;)</span><br></pre></td></tr></table></figure></p><p>输出:<br><img src="/img/blog/df/group3.png" alt></p><h3 id="4-行转列-group-concat"><a href="#4-行转列-group-concat" class="headerlink" title="4. 行转列: group_concat"></a>4. 行转列: group_concat</h3><p>sql中的group_concat可以实现将同组的多行字段拼接成一列，也就是行转列，numpy.unique可以轻松实现，比如下面我们合并每个二级分类下的所有分数(例子并不很恰当，学操作就行):</p><ul><li><p>sql</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    cat1, cat2,</span><br><span class="line">    <span class="keyword">count</span>(<span class="keyword">name</span>), <span class="keyword">avg</span>(score), <span class="keyword">sum</span>(score), <span class="keyword">min</span>(score), <span class="keyword">max</span>(score),</span><br><span class="line">    <span class="keyword">count</span>(<span class="keyword">distinct</span> score), <span class="keyword">group_concat</span>(score separator  <span class="string">','</span>)</span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    multi_category_data</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span></span><br><span class="line">    cat1, cat2</span><br></pre></td></tr></table></figure></li><li><p>dataframe</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.groupby([<span class="string">'cat1'</span>, <span class="string">'cat2'</span>]).agg(&#123;<span class="string">'name'</span>: [np.size], <span class="string">'score'</span>: [np.mean, np.sum, np.min, np.max, my_distinct, np.unique]&#125;)</span><br></pre></td></tr></table></figure></li></ul><p>输出:<br><img src="/img/blog/df/group4.png" alt></p><p>先到这里，后续再补充~</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在分析数据时，dataframe的很多方法和sql是类似的，本文总结一些二者中的相通问题，方便互相转移，下面以mysql语法为例。&lt;br&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="pandas" scheme="http://yoursite.com/tags/pandas/"/>
    
      <category term="dataframe" scheme="http://yoursite.com/tags/dataframe/"/>
    
      <category term="sql" scheme="http://yoursite.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>xgboost 特征重要性</title>
    <link href="http://yoursite.com/1781693973.html"/>
    <id>http://yoursite.com/1781693973.html</id>
    <published>2018-11-17T16:00:00.000Z</published>
    <updated>2019-03-28T09:08:02.327Z</updated>
    
    <content type="html"><![CDATA[<h1 id="官方解释"><a href="#官方解释" class="headerlink" title="官方解释"></a>官方解释</h1><p>Python中的xgboost可以通过get_fscore获取特征重要性，先看看官方对于这个方法的<a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html" target="_blank" rel="noopener">说明</a>:</p><blockquote><p>get_score(fmap=’’, importance_type=’weight’)</p><p>Get feature importance of each feature. Importance type can be defined as:</p><ul><li>‘weight’: the number of times a feature is used to split the data across all trees.</li><li>‘gain’: the average gain across all splits the feature is used in.</li><li>‘cover’: the average coverage across all splits the feature is used in.</li><li>‘total_gain’: the total gain across all splits the feature is used in.</li><li>‘total_cover’: the total coverage across all splits the feature is used in.</li></ul></blockquote><p>看释义不直观，下面通过训练一个简单的模型，输出这些重要性指标，再结合释义进行解释。<br><a id="more"></a></p><h1 id="代码实践"><a href="#代码实践" class="headerlink" title="代码实践"></a>代码实践</h1><p>首先构造10个样例的样本，每个样例有两维特征，标签为0或1，二分类问题:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">sample_num = <span class="number">10</span></span><br><span class="line">feature_num = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">data = np.random.randn(sample_num, feature_num)</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">label = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, sample_num)</span><br></pre></td></tr></table></figure></p><p>输出data和label:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># data:</span><br><span class="line">array([[ 1.76405235,  0.40015721],</span><br><span class="line">       [ 0.97873798,  2.2408932 ],</span><br><span class="line">       [ 1.86755799, -0.97727788],</span><br><span class="line">       [ 0.95008842, -0.15135721],</span><br><span class="line">       [-0.10321885,  0.4105985 ],</span><br><span class="line">       [ 0.14404357,  1.45427351],</span><br><span class="line">       [ 0.76103773,  0.12167502],</span><br><span class="line">       [ 0.44386323,  0.33367433],</span><br><span class="line">       [ 1.49407907, -0.20515826],</span><br><span class="line">       [ 0.3130677 , -0.85409574]])</span><br><span class="line"># label:</span><br><span class="line">array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1])</span><br></pre></td></tr></table></figure></p><p>训练，这里为了便于下面计算，将树深度设为3(‘max_depth’: 3)，只用一棵树(num_boost_round=1):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line">train_data = xgb.DMatrix(data, label=label)</span><br><span class="line">params = &#123;<span class="string">'max_depth'</span>: <span class="number">3</span>&#125;</span><br><span class="line">bst = xgb.train(params, train_data, num_boost_round=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>输出重要性指标:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> importance_type <span class="keyword">in</span> (<span class="string">'weight'</span>, <span class="string">'gain'</span>, <span class="string">'cover'</span>, <span class="string">'total_gain'</span>, <span class="string">'total_cover'</span>):</span><br><span class="line">    print(<span class="string">'%s: '</span> % importance_type, bst.get_score(importance_type=importance_type))</span><br></pre></td></tr></table></figure></p><p>结果:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">weight:  &#123;&apos;f0&apos;: 1, &apos;f1&apos;: 2&#125;</span><br><span class="line">gain:  &#123;&apos;f0&apos;: 0.265151441, &apos;f1&apos;: 0.375000015&#125;</span><br><span class="line">cover:  &#123;&apos;f0&apos;: 10.0, &apos;f1&apos;: 4.0&#125;</span><br><span class="line">total_gain:  &#123;&apos;f0&apos;: 0.265151441, &apos;f1&apos;: 0.75000003&#125;</span><br><span class="line">total_cover:  &#123;&apos;f0&apos;: 10.0, &apos;f1&apos;: 8.0&#125;</span><br></pre></td></tr></table></figure></p><p>画出唯一的一棵树图:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xgb.to_graphviz(bst, num_trees=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><p><img src="/img/blog/xgboost/tree.png" alt="one"></p><p>下面就结合这张图，解释下各指标含义:</p><ol><li>weight:  {‘f0’: 1, ‘f1’: 2}<br>在所有树中，某特征被用来分裂节点的次数，在本例中，可见分裂第1个节点时用到f0，分裂第2，3个节点时用到f1，所以weight_f0 = 1, weight_f1 = 2。</li><li>total_cover:  {‘f0’: 10.0, ‘f1’: 8.0}<br>第1个节点，f0被用来对所有10个样例进行分裂，之后的节点中f0没再被用到，所以f0的total_cover为10.0，此时f0 &gt;= 0.855563045的样例有5个，落入右子树；<br>第2个节点，f1被用来对上面落入右子树的5个样例进行分裂，其中f1 &gt;= -0.178257734的样例有3个，落入右子树；<br>第3个节点，f1被用来对上面落入右子树的3个样例进行分裂。<br>总结起来，f0在第1个节点分裂了10个样例，所以total_cover_f0 = 10，f1在第2、3个节点分别用于分裂5、3个样例，所以total_cover_f1 = 5 + 3 = 8。total_cover表示在所有树中，某特征在每次分裂节点时处理(覆盖)的所有样例的数量。</li><li>cover:  {‘f0’: 10.0, ‘f1’: 4.0}<br>cover = total_cover / weight，在本例中，cover_f0 = 10 / 1，cover_f1 = 8 / 2 = 4.</li><li>total_gain:  {‘f0’: 0.265151441, ‘f1’: 0.75000003}<br>在所有树中，某特征在每次分裂节点时带来的总增益，如果用熵或基尼不纯衡量分裂前后的信息量分别为i0和i1，则增益为(i0 - i1)。</li><li>gain:  {‘f0’: 0.265151441, ‘f1’: 0.375000015}<br>gain = total_gain / weight，在本例中，gain_f0 = 0.265151441 / 1，gain_f1 = 75000003 / 2 = 375000015.</li></ol><p>在平时的使用中，多用total_gain来对特征重要性进行排序。</p><h1 id="By-The-Way"><a href="#By-The-Way" class="headerlink" title="By The Way"></a>By The Way</h1><p>构造xgboost分类器还有另外一种方式，这种方式类似于sklearn中的分类器，采用fit, transform形式训练模型:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"></span><br><span class="line">cls = XGBClassifier(base_score=<span class="number">0.5</span>, booster=<span class="string">'gbtree'</span>, colsample_bylevel=<span class="number">1</span>,</span><br><span class="line">       colsample_bytree=<span class="number">1</span>, gamma=<span class="number">0</span>, learning_rate=<span class="number">0.07</span>, max_delta_step=<span class="number">0</span>,</span><br><span class="line">       max_depth=<span class="number">3</span>, min_child_weight=<span class="number">1</span>, missing=<span class="keyword">None</span>, n_estimators=<span class="number">300</span>,</span><br><span class="line">       n_jobs=<span class="number">1</span>, nthread=<span class="keyword">None</span>, objective=<span class="string">'binary:logistic'</span>, random_state=<span class="number">0</span>,</span><br><span class="line">       reg_alpha=<span class="number">0</span>, reg_lambda=<span class="number">1</span>, scale_pos_weight=<span class="number">1</span>, seed=<span class="keyword">None</span>,</span><br><span class="line">       silent=<span class="keyword">True</span>, subsample=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="comment"># cls.fit(data, label)</span></span><br></pre></td></tr></table></figure></p><p>采用下面的方式获取特征重要性指标:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> importance_type <span class="keyword">in</span> (<span class="string">'weight'</span>, <span class="string">'gain'</span>, <span class="string">'cover'</span>, <span class="string">'total_gain'</span>, <span class="string">'total_cover'</span>):</span><br><span class="line">    print(<span class="string">'%s: '</span> % importance_type, cls.get_booster().get_score(importance_type=importance_type))</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;官方解释&quot;&gt;&lt;a href=&quot;#官方解释&quot; class=&quot;headerlink&quot; title=&quot;官方解释&quot;&gt;&lt;/a&gt;官方解释&lt;/h1&gt;&lt;p&gt;Python中的xgboost可以通过get_fscore获取特征重要性，先看看官方对于这个方法的&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/python/python_api.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;说明&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;get_score(fmap=’’, importance_type=’weight’)&lt;/p&gt;
&lt;p&gt;Get feature importance of each feature. Importance type can be defined as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‘weight’: the number of times a feature is used to split the data across all trees.&lt;/li&gt;
&lt;li&gt;‘gain’: the average gain across all splits the feature is used in.&lt;/li&gt;
&lt;li&gt;‘cover’: the average coverage across all splits the feature is used in.&lt;/li&gt;
&lt;li&gt;‘total_gain’: the total gain across all splits the feature is used in.&lt;/li&gt;
&lt;li&gt;‘total_cover’: the total coverage across all splits the feature is used in.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;看释义不直观，下面通过训练一个简单的模型，输出这些重要性指标，再结合释义进行解释。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="tree" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/tree/"/>
    
    
      <category term="xgboost" scheme="http://yoursite.com/tags/xgboost/"/>
    
      <category term="特征重要性" scheme="http://yoursite.com/tags/%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>链家小区均价数据爬取</title>
    <link href="http://yoursite.com/2739431502.html"/>
    <id>http://yoursite.com/2739431502.html</id>
    <published>2018-09-23T16:00:00.000Z</published>
    <updated>2019-03-28T09:08:24.350Z</updated>
    
    <content type="html"><![CDATA[<p>最近有个需求，需要了解市场上小区的均价，于是试着写了个爬虫把链家上小区的信息爬取了一下。这次的爬虫任务比较简单，数据量不大，爬取链接中也没加密字段等反爬取策略，感觉还挺适合作为爬虫入门的例子。下载数据主要利用python requests库来完成，解析html页面用到xpath，下面分享些技巧和经验。<br><a id="more"></a></p><blockquote><ol><li>开发环境:<br>python3.6<br>pip install requests<br>pip install lxml</li><li>浏览器:<br>Chrome</li></ol></blockquote><h2 id="1-网站分析"><a href="#1-网站分析" class="headerlink" title="1. 网站分析"></a>1. 网站分析</h2><p>链家网上有小区专门的页面，域名格式为: 城市代码.lianjia.com/xiaoqu/城区代码/页码，期中页码格式为pg1、pg2这样，如果不加页码，则默认显示第1页数据。比如下面显示北京西城区的小区情况，可以看到有1716个小区，小区的名字、均价等信息都有。页面下方有页码。通过更改城市代码、城区名以及页码，就可以获取对应的小区信息。<br><img src="/img/blog/spider-lianjia/zone1.jpg" width="100%" height="50%"><br>如果想要下载全国城市小区价格信息，大致分为3个步骤:</p><ol><li>获取城市代码</li><li>获取每个城市的城区代码</li><li>获取某城区所有页码数，拼接url, 下载具体某个城市的某城区信息</li></ol><p>下面按照3, 2, 1的顺序讲解，先把一个城区的数据搞下来，再想办法扩展到一个城市和全国范围。</p><h2 id="2-下载城区数据"><a href="#2-下载城区数据" class="headerlink" title="2. 下载城区数据"></a>2. 下载城区数据</h2><h3 id="1-定位数据位置"><a href="#1-定位数据位置" class="headerlink" title="1. 定位数据位置"></a>1. 定位数据位置</h3><p>浏览器选择Chrome，打开Chrome开发者工具(在页面上单击右键选择<strong>检查</strong>菜单)，依次点击<strong>Network</strong>栏，<strong>Doc</strong>栏，会显示本次网络请求到的页面，点击左下<strong>Name</strong>窗口中的条目，即可在右侧窗口中看到此页面的相关内容，如Headers(请求头)、Preview(预览)、Response(返回内容)、Cookies、Timing。点击<strong>Preview</strong>可以看到所需要的数据就包含在一个静态页面中，所以只要把这个页面下载下来，就可以提取其中的数据了。<br><img src="/img/blog/spider-lianjia/zone2.jpg" width="100%" height="50%"></p><blockquote><p>爬虫任务的第一步就是要明确自己需要的数据在哪里。通常在页面上看到的早已渲染好的数据在后端会以两种方式传递给前端:</p><ol><li>一种即是本例中，数据是早已嵌在页面中。通常这种情况数据在<strong>Doc</strong>中可以看到；</li><li>另一种情况中，页面结构和数据是分离的，数据通常以json格式通过ajax异步请求返回给客户端，再通过js程序加载到页面结构中。这种情况下数据可以在<strong>XHR</strong>栏看到。</li></ol></blockquote><blockquote><p>想要定位自己所需的数据在哪，需要借助浏览器的开发者工具，分析一次请求的过程都发生了什么，先看看<strong>Doc</strong>、<strong>XHR</strong>栏里的内容，依次点点每个请求内容(<strong>Name</strong>栏中的条目)，其中<strong>Doc</strong>栏中的内容在预览情况下比较容易看，就是一个页面，而<strong>XHR</strong>栏下的通常是json格式的数据，就需要好好和页面上渲染好的数据作比较了。</p></blockquote><h3 id="2-下载数据"><a href="#2-下载数据" class="headerlink" title="2. 下载数据"></a>2. 下载数据</h3><p>接下来我们就可以开始写代码爬数据了。<br>首先定义一个Spider类:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class Spider(object):</span><br><span class="line"></span><br><span class="line">    def __init__(self, city):</span><br><span class="line">        self.city = city</span><br><span class="line">        self.domain = &apos;https://%s.lianjia.com&apos; % city</span><br></pre></td></tr></table></figure></p><p>构造方法接收一个城市代码，在本例中即是<strong>bj</strong>，构造方法中为成员变量domain赋值。<br>接下来定义一个download_page方法，用于下载一个页面。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def download_page(self, url, file_out):</span><br><span class="line">    res = requests.get(url)</span><br><span class="line">    content = res.text</span><br><span class="line">    with open(file_out, &apos;w&apos;) as fo:</span><br><span class="line">        fo.write(content)</span><br></pre></td></tr></table></figure></p><p>注意参数url格式为self.domain/xiaoqu/城区代码/页码。<br>编写一个main方法运行试验下，这里先将城区和页码固定:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def main():</span><br><span class="line">    city = &apos;bj&apos;</span><br><span class="line">    spider = Spider(city)</span><br><span class="line">    page_file = &apos;test.html&apos;</span><br><span class="line">    residence = &apos;xicheng&apos;</span><br><span class="line">    page = &apos;pg2&apos;</span><br><span class="line">    url = &apos;%s/xiaoqu/%s/%s&apos; % (spider.domain, residence, page)</span><br><span class="line">    spider.download_page(url, page_file)</span><br></pre></td></tr></table></figure></p><p>运行后可以看到当前目录下多了一个test.html</p><blockquote><p>将每次网络请求的数据保存下来是个好习惯，有以下好处:</p><ol><li>后续开发解析模块可以利用这些文件，不必重新请求数据，减少时延，节省时间，同时也能减少请求次数，防止被ban;</li><li>方便排查问题，如果程序上线了结果解析出错，可以查看文件内容，看看是网站改版了还是请求的页面错误等。</li></ol></blockquote><h2 id="3-解析数据"><a href="#3-解析数据" class="headerlink" title="3. 解析数据"></a>3. 解析数据</h2><h3 id="1-找到节点xpath"><a href="#1-找到节点xpath" class="headerlink" title="1. 找到节点xpath"></a>1. 找到节点xpath</h3><p>解析用到xpath，开发者工具对xpath支持很好。先看下面的例子:<br><img src="/img/blog/spider-lianjia/zone3.jpg" width="100%" height="50%"><br>按照步骤操作后可以获得一个节点的xpath。在上例中，可以获得价格的xpath:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;/html/body/div[4]/div[1]/ul/li[1]/div[2]/div[1]/div[1]/span&apos;</span><br></pre></td></tr></table></figure></p><p>通过开发者工具的<strong>Console</strong>栏可以方便地验证xpath:<br><img src="/img/blog/spider-lianjia/zone4.jpg" width="100%" height="50%"><br>在Console栏中的命令行输入$x()方法，将上面复制的xpath粘贴进去，$x()方法接收xpath路径作为参数，返回对应的节点列表，通过[0]选择第1个节点，节点的innterText变量保存了对应的内容。通过更改xpath，就可以获取各个小区的名字和价格等信息了。</p><h3 id="2-优化xpath"><a href="#2-优化xpath" class="headerlink" title="2. 优化xpath"></a>2. 优化xpath</h3><p>上面通过开发者工具获取的xpath是一条绝对路径，可以看到路径上有很多节点，如果以后网站改版了，路径上的某个节点改变了，那这条xpath就不能指向正确的位置了。所以通常可以利用节点的相对位置和属性等来写出更友好的xpath，比如我将上面4条xpath改写一下:<br><img src="/img/blog/spider-lianjia/zone5.jpg" width="100%" height="50%"><br>同样获取到了需要的数据，而且此时看xpath也容易理解，比如第1条取小区名，是取class=”listContent”的ul下，第1个li下，class=”title”的div下，a标签的内容；如果想要取价格，就把div的class改为totalPrice，a标签换成span。这比绝对路径上一堆节点好理解多了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$x(&apos;//ul[@class=&quot;listContent&quot;]/li[1]//div[@class=&quot;title&quot;]/a&apos;)[0].innerText</span><br><span class="line">$x(&apos;//ul[@class=&quot;listContent&quot;]/li[1]//div[@class=&quot;totalPrice&quot;]/span&apos;)[0].innerText</span><br><span class="line">$x(&apos;//ul[@class=&quot;listContent&quot;]/li[2]//div[@class=&quot;title&quot;]/a&apos;)[0].innerText</span><br><span class="line">$x(&apos;//ul[@class=&quot;listContent&quot;]/li[2]//div[@class=&quot;totalPrice&quot;]/span&apos;)[0].innerText</span><br></pre></td></tr></table></figure></p><blockquote><p>Chrome的命令行提供了很多方便的工具，$x()即是其一，利用好了事半功倍，更多知识请参见<a href="https://developers.google.com/web/tools/chrome-devtools/console/command-line-reference?hl=zh-cn" target="_blank" rel="noopener">Chrome命令行</a>。</p></blockquote><h3 id="3-python代码"><a href="#3-python代码" class="headerlink" title="3. python代码"></a>3. python代码</h3><p>在Spider类中添加parse方法:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def parse(self, page_file):</span><br><span class="line">    with open(page_file) as f:</span><br><span class="line">        content = f.read()</span><br><span class="line">        selector = etree.HTML(content)</span><br><span class="line">        # 获取li数量</span><br><span class="line">        path = &apos;//ul[@class=&quot;listContent&quot;]/li&apos;</span><br><span class="line">        size = len(selector.xpath(path))</span><br><span class="line">        # 遍历li节点</span><br><span class="line">        for i in range(1, size + 1):</span><br><span class="line">            li_path = &apos;//ul[@class=&quot;listContent&quot;]/li[%s]&apos; % i</span><br><span class="line">            # 获取小区名</span><br><span class="line">            path = li_path + &apos;//div[@class=&quot;title&quot;]/a&apos;</span><br><span class="line">            name = selector.xpath(path)[0].text</span><br><span class="line">            # 获取价格</span><br><span class="line">            path = li_path + &apos;//div[@class=&quot;totalPrice&quot;]/span&apos;</span><br><span class="line">            price = selector.xpath(path)[0].text</span><br><span class="line">            print(name, price)</span><br></pre></td></tr></table></figure></p><p>运行试验下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def main():</span><br><span class="line">    city = &apos;bj&apos;</span><br><span class="line">    spider = Spider(city)</span><br><span class="line">    page_file = &apos;test.html&apos;</span><br><span class="line">    residence = &apos;xicheng&apos;</span><br><span class="line">    page = &apos;pg2&apos;</span><br><span class="line">    url = &apos;%s/xiaoqu/%s/%s&apos; % (spider.domain, residence, page)</span><br><span class="line">    # spider.download_page(url, page_file)</span><br><span class="line">    spider.parse(page_file)</span><br></pre></td></tr></table></figure></p><p>输出:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">锦官苑 139610</span><br><span class="line">马甸南村 140382</span><br><span class="line">玺源台 99726</span><br><span class="line">黄寺大街24号院 134787</span><br><span class="line">新街口西里三区 111055</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>需要的数据就都有了！</p><h2 id="3-其他工作"><a href="#3-其他工作" class="headerlink" title="3. 其他工作"></a>3. 其他工作</h2><p>至于如何按页码、按城区、按城市下载全国数据，代码都已经都实现了，也不难，有时间下回分解，中秋快乐！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近有个需求，需要了解市场上小区的均价，于是试着写了个爬虫把链家上小区的信息爬取了一下。这次的爬虫任务比较简单，数据量不大，爬取链接中也没加密字段等反爬取策略，感觉还挺适合作为爬虫入门的例子。下载数据主要利用python requests库来完成，解析html页面用到xpath，下面分享些技巧和经验。&lt;br&gt;
    
    </summary>
    
      <category term="爬虫" scheme="http://yoursite.com/categories/%E7%88%AC%E8%99%AB/"/>
    
    
      <category term="爬虫" scheme="http://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>在多台电脑上写GitHub Pages博客</title>
    <link href="http://yoursite.com/3974204864.html"/>
    <id>http://yoursite.com/3974204864.html</id>
    <published>2018-09-02T16:00:00.000Z</published>
    <updated>2019-05-27T10:12:46.170Z</updated>
    
    <content type="html"><![CDATA[<p>之前在公司的mac上写过GitHub Pages，最近离职了，于是想用自己的windows本继续写。本以为安装好nodejs，npm等环境再git pull一下就可以在windows本上写博客，实践了才发现一些问题。git pull下来的内容根本没办法直接在本地显示博客内容，因为少了很多配置等文件。下图分别是mac上(已经拷贝到windows本)可以运行的博客和在windows本上pull下来的文件：<br><a id="more"></a></p><ul><li>mac上可以运行的博客</li></ul><p><img src="/img/blog/write-github-pages-among-different-computers/mac_hexo.jpg" width="70%" height="50%"></p><ul><li>git上pull下来的文件</li></ul><p><img src="/img/blog/write-github-pages-among-different-computers/git_hexo.jpg" width="70%" height="50%"></p><p>可以看到在git上的内容少了几个目录，如node_modules(node.js执行需要的库)、scaffolds(生成md文件时用到的模板，可自定义: hexo new [post/page/draft] <title>)、source(自己写的md文件)、themes(主题)，以及package.json、package-lock.json等文件。</title></p><p>之前对node.js，hexo这套东西也不太了解，通过这次折腾算是多了些理解。GitHub Pages保存的内容顾名思义，就是一些html页面，以及支持这些页面显示的字体(fonts)、图片(img), 标签(tags)、js、css等，在执行hexo d命令时，以上的内容会提交到git仓库的master分支上；<br>而支撑生成这些静态页面的md文件(scaffolds、source)，主题(themes)，以及在本地调试用到的node.js环境(node_modules、package.json、package-lock.json)则不会被提交。</p><p>知道了这些就可以利用git的分支解决这个问题了：</p><ol><li>支撑生成这些静态页面的md文件(scaffolds、source)，主题(themes)等是需要保存的，可以提交到新的分支上；</li><li>本地调试用到的node.js环境(node_modules)就不必提交了，可能各个电脑安装的版本也不一样，需要时 npm install 一条命令就生成了。<blockquote><p>由于我们是从已有博客恢复环境，而不是从头开始创建环境，所以 <strong>hexo init</strong> 命令不需要执行，此命令会初始化hexo所需环境及基本配置，下图即是运行后生成的目录结构。但以下目录及文件都是已有的(在你的另一台电脑的硬盘上，而不是git仓库)，可以直接拷贝过来。但是我建议node_modulds就别拷贝了，可能不同电脑上版本不同。但是package.json、package-lock.json是需要提交的，其中保存了hexo及package的版本等信息，执行<strong>npm install</strong> 需要这两个文件。<br>这里要注意执行<strong>npm install</strong> 后，由于两台电脑上hexo及package版本不一致，这两个文件也可能会被改写，所以如果需要频繁地在多台电脑上写博客，这两个文件可以不再提交。<br><img src="/img/blog/write-github-pages-among-different-computers/hexo_init.jpg" width="90%" height="50%"></p></blockquote></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建新分支保存md文件及主题等</span><br><span class="line">git checkout -b hexo</span><br><span class="line"># 编辑.gitignore文件，在新分支上忽略node_modules等</span><br><span class="line">vi .gitignore</span><br><span class="line"># 提交需要保存的文件</span><br><span class="line">git add ... git commit ... git push origin hexo</span><br></pre></td></tr></table></figure><p>以后换了新电脑，执行下面的命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 克隆代码库</span><br><span class="line">git clone your/github/repo dir/for/blog</span><br><span class="line"># 切换分支</span><br><span class="line">cd dir/for/blog</span><br><span class="line">git checkout hexo</span><br><span class="line"># 安装node.js环境</span><br><span class="line">npm install</span><br><span class="line"># 测试</span><br><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure></p><p>以后写md、调主题就在hexo分支上进行，记得最后都<strong>git add … git commit … git push origin hexo</strong>，以便保存到git仓库。在hexo分支上运行<strong>hexo d</strong>就可以，实际上是将<strong>hexo g</strong>生成的静态pages推送到主分支上(这些操作都由 hexo-deployer-git工具完成，对我们来讲是透明的)。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前在公司的mac上写过GitHub Pages，最近离职了，于是想用自己的windows本继续写。本以为安装好nodejs，npm等环境再git pull一下就可以在windows本上写博客，实践了才发现一些问题。git pull下来的内容根本没办法直接在本地显示博客内容，因为少了很多配置等文件。下图分别是mac上(已经拷贝到windows本)可以运行的博客和在windows本上pull下来的文件：&lt;br&gt;
    
    </summary>
    
      <category term="博客搭建" scheme="http://yoursite.com/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="GitHub Pages" scheme="http://yoursite.com/tags/GitHub-Pages/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Python2 编码问题</title>
    <link href="http://yoursite.com/2385407591.html"/>
    <id>http://yoursite.com/2385407591.html</id>
    <published>2018-04-28T16:00:00.000Z</published>
    <updated>2019-03-25T09:47:52.602Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一些定义"><a href="#一些定义" class="headerlink" title="一些定义"></a>一些定义</h2><ul><li><strong>字符(character)</strong><br><br><strong>字符</strong>是文字的最小的组成单位，其为一种抽象定义(不要与 java 或 c 中的 char 类型混淆，后者为特定计算机语言的数据类型)，取决于语言或是上下文环境，比如’A’, ‘a’为英文中的字符，’纺’,’织’是汉语中的字符(注意绞丝旁并不能称为是一个字符，因为在汉语中，它无法单独成为一个字) 。<a id="more"></a></li><li><p><strong>图像字符(glyph)</strong><br><br>人们在交谈时通过独特的发音来表达一个字符，而当在屏幕或是纸面上时，则是通过一些特定图形来表达一个字符。比如在汉字中用一条横线来表示’一’这个字符。这个图像化的形象即被称为<strong>图像字符</strong>，在计算机中可以通过矢量图表示。</p></li><li><p><strong>字符串(characters/string)</strong><br><br><strong>字符串</strong>由若干字符组成的串。</p></li><li><p><strong>码点(code point)</strong><br><br>码点也有译为码位(code position)，是一个整数，常用16进制表示。Unicode标准就是维护了一张<strong>字符与码点的映射表</strong>，说白了，就是将一个字符用某个唯一的整数表示，这样全世界的计算机上都保存这样一张表，数据传输时只需要传输一堆数字就好，再用这张表去解析，找到对应的字符即可，而无需去传输字符所对应的矢量图。这就是标准的作用。<br><br>下图是’一’的 Unicode 编码示例(图片源自<a href="https://www.charbase.com/4e00-unicode-cjk-unified-ideograph" target="_blank" rel="noopener">Charbase</a>):<br><br><img src="/img/blog/one.png" alt="one"></p></li></ul><h2 id="既然有了-Unicode，为什么还有一众编码方式？"><a href="#既然有了-Unicode，为什么还有一众编码方式？" class="headerlink" title="既然有了 Unicode，为什么还有一众编码方式？"></a>既然有了 Unicode，为什么还有一众编码方式？</h2><p>现在我们知道了，世界上有这么一个统一的标准，那为什么还有 latin1, utf8, gbk 这些编码方式呢？为何不只用这一种编码方式，也省去了 decode, encode 的麻烦了。其实这是概念上的混淆。如果你还不知道自己错在哪了，请思考一个问题，作为程序员，我们都或多或少地了解 MVC 模式，那我想问，既然 MVC 这么好，为什么还要用 MFC(vc++框架), struts(java web 框架), ci(php 框架)呢？相信你可以理解这个荒唐的问题。</p><blockquote><p>MVC 是一种设计模式，一种思想，将 model，view, controller 解耦。而上面提到的几种框架，其实是对这种设计模式的针对不同的场景进行的实现。可以将 MVC当作一个类，而具体干活的，其实是需要 new 一个对象出来，也就是MFC等一众对 MVC 思想的具体实现。</p></blockquote><p>与 MVC 这个问题类似，Unicode 其实是多种编码体系(如ISO/IEC 10646)中的一种，而具体实现这种体系的，则为 UTF(Unicode Transformation Format)，包括 utf8, utf16, utf32等编码方式。</p><blockquote><p>Unicode标准<strong>的确</strong>维护了一张<strong>字符与码点的映射表</strong>，所以你可以查看某个字符的 Unicode 编码，正如在上面’一’的 Unicode 编码示例图中可见其 Unicode 编码为’\u4e00’。然而对于码点在网络传输或物理存储具体要如何操作，如码点前置0怎么处理，用多少字节表示一个字符等问题，Unicode标准并未规定，具体是由UTF来实现的。</p></blockquote><p>写到这里，上面提到的所有概念和内容与python没有半毛钱关系，对于任何编程语言上面的概念都是放诸四海皆准的。上文所提到的 Unicode 全部指代 Unicode 标准，千万不要和 python 中的 unicode 类型混淆(注意两个概念在本文中用首字母的大小写来区别)！</p><p>每种编码方式都有各自的特点，如汉字’一’用 gbk 及 utf16 编码占2个字节，用 utf8编码则占3个字节，’a’用 utf8编码则只占一个字节，用 utf16仍然占用2个字节，而 Unicode 统一使用4个字节来表示所有字符，但是对于定长的东西，在内存中寻址就很快很方便，这也是<strong>在计算机内存中统一使用Unicode，而当要保存或传输数据时，转换成 UTF 编码</strong>(当然也可以采用其他编码)的原因。</p><blockquote><p>gbk是针对汉字的编码方式，虽然可以用较少的字节来表示一个汉语字符，但对于很多其他国家的字符就无能为力了，而 utf 编码则基本囊括了世界上所有语言的字符集；<br>utf16，utf32分别用2、4个字节表示一个字符，然而对于英文等语言环境来讲，一个字节完全可以表示一个字符，就会浪费存储空间。</p></blockquote><p>不同的编码方式都有其诞生及存在的合理性，不能只凭字符占用字节数，能表达的语言种类或是大小端处理等来衡量优劣，适合的就是最好的。所以，我们无法用一种编码方式走遍天下，那就得好好了解下如何在多种编码方式中处理数据，下面就来看下 python 中对于字符编码的处理。</p><h2 id="Python2中编码的转换"><a href="#Python2中编码的转换" class="headerlink" title="Python2中编码的转换"></a>Python2中编码的转换</h2><p>在python2中，字符串可以用 unicode 或 str 这两种类型来表示。<br>unicode类型的字符串由若干Unicode字符组成，本文中称之为<strong>unicode串</strong>，注意 unicode 与 unicode串是类与实例的关系，如下面代码中，a，b，c，d都是unicode串，a，b，c，d 的类型都是unicode：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf8 -*-</span><br><span class="line">a = u&apos;a&apos;</span><br><span class="line">b = u&apos;一&apos;</span><br><span class="line">c = u&apos;一a&apos;</span><br><span class="line">d = u&apos;一a\u4e00&apos; # 汉字&apos;一&apos;的 unicode 编码为\u4e00</span><br><span class="line">e = u&apos;一a\u4e00\x61\141&apos;</span><br><span class="line">print a, b, c, d, e</span><br><span class="line">print type(a), type(b), type(c), type(d), type(e)</span><br></pre></td></tr></table></figure></p><p>输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a 一 一a 一a一 一a一aa</span><br><span class="line">&lt;type &apos;unicode&apos;&gt; &lt;type &apos;unicode&apos;&gt; &lt;type &apos;unicode&apos;&gt; &lt;type &apos;unicode&apos;&gt; &lt;type &apos;unicode&apos;&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>如果对变量 e 的内容有疑问，可以参考<a href="http://python-reference.readthedocs.io/en/latest/docs/str/escapes.html" target="_blank" rel="noopener">这篇文章</a></p></blockquote><p>str类型的字符串其实为字节序列，本文中称之为<strong>str串</strong>，一个str串的编码方式是需要指定的，这点和 unicode 串很不一样。因为 unicode 串一定是由 Unicode字符组成，这个规则是确定的。但是 python 不知道一个 str 串是采用了何种编码方式，只能使用默认的编码方式来处理，这个过程就有可能出错，事实上关于字符串转码的问题大多就出现在这里。</p><p>在 python2 中，将 unicode串转换成 str串称为编码(encode), 而将str串转换成 unicode串称之为解码(decode)。</p><h3 id="编码-encode"><a href="#编码-encode" class="headerlink" title="编码(encode):"></a>编码(encode):</h3><p>将内存中的unicode串保存到外存时，需要将之编码(encode)为 str串(即字节序列)，看下面的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># # -*- coding: utf8 -*-</span><br><span class="line">one = u&apos;一&apos;</span><br><span class="line">with open(&apos;one.txt&apos;, &apos;w&apos;) as f:</span><br><span class="line">    f.write(one)</span><br></pre></td></tr></table></figure></p><p>运行报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnicodeEncodeError: &apos;ascii&apos; codec can&apos;t encode character u&apos;\u4e00&apos; in position 0: ordinal not in range(128)</span><br></pre></td></tr></table></figure></p><p>意思是说采用 ascii 编解码标准无法对’一’进行编码，这是因为f.write(one)这行代码在执行时被解释成f.write(one.encode(‘ascii’))。python 默认会采用 ascci 编解码标准对unicode串进行编码，而汉字’一’的Unicode 编码为4e00(16进制)，超出了 ascii 编解码标准的上限128，所以报错。</p><p>正确做法是在将变量保存至外存时，显式地指定恰当的编码方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf8 -*-</span><br><span class="line">one = u&apos;一&apos;</span><br><span class="line">with open(&apos;one.txt&apos;, &apos;w&apos;) as f:</span><br><span class="line">    f.write(one.encode(&apos;utf8&apos;))</span><br></pre></td></tr></table></figure></p><h3 id="解码-decode"><a href="#解码-decode" class="headerlink" title="解码(decode):"></a>解码(decode):</h3><p>当需要将不同编码类型的字符串放在一起处理时(比如从数据库中读入一个字段，在内存中其为一个unicode串，将之与一个 utf8编码的文件中的第一行数据拼接成一个字符串)，最好将 str串解码成unicode串，看下面的代码示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf8 -*-</span><br><span class="line">database_field = u&apos;一&apos;</span><br><span class="line">file_first_line = &apos;二&apos;</span><br><span class="line">print database_field, type(database_field)</span><br><span class="line">print file_first_line, type(file_first_line)</span><br><span class="line">print database_field \</span><br><span class="line">      + file_first_line  # 分行是为方便查看是哪行转换出错</span><br></pre></td></tr></table></figure></p><p>运行报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">一 &lt;type &apos;unicode&apos;&gt;</span><br><span class="line">二 &lt;type &apos;str&apos;&gt;</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/baidu/PhpstormProjects/scripts_dev/python/grammer/coding.py&quot;, line 7, in &lt;module&gt;</span><br><span class="line">    + file_first_line  # 分行是为方便查看是哪行转换出错</span><br><span class="line">UnicodeDecodeError: &apos;ascii&apos; codec can&apos;t decode byte 0xe4 in position 0: ordinal not in range(128)</span><br></pre></td></tr></table></figure></p><p>可以看到单独处理（输出）两个变量是没问题的，不过放在一起就完蛋了。从报错信息可以看到是对file_first_line按照ascii decode 时出错，原因不难理解，unicode串与 str串类型不一致，无法直接拼接，python 在尝试将 str串解码为 unicode 串时，采用了错误的 ascii 编解码标准。</p><p>可以通过将二者统一转换成一种类型来解决：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf8 -*-</span><br><span class="line">database_field = u&apos;一&apos;</span><br><span class="line">file_first_line = &apos;二&apos;</span><br><span class="line">print database_field, type(database_field)</span><br><span class="line">print file_first_line, type(file_first_line)</span><br><span class="line">print database_field + file_first_line.decode(&apos;utf8&apos;), \</span><br><span class="line">    type(database_field + file_first_line.decode(&apos;utf8&apos;))</span><br><span class="line">print database_field.encode(&apos;utf8&apos;) + file_first_line, \</span><br><span class="line">    type(database_field.encode(&apos;utf8&apos;) + file_first_line)</span><br></pre></td></tr></table></figure></p><p>运行如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">一 &lt;type &apos;unicode&apos;&gt;</span><br><span class="line">二 &lt;type &apos;str&apos;&gt;</span><br><span class="line">一二 &lt;type &apos;unicode&apos;&gt;</span><br><span class="line">一二 &lt;type &apos;str&apos;&gt;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一些定义&quot;&gt;&lt;a href=&quot;#一些定义&quot; class=&quot;headerlink&quot; title=&quot;一些定义&quot;&gt;&lt;/a&gt;一些定义&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;字符(character)&lt;/strong&gt;&lt;br&gt;&lt;br&gt;&lt;strong&gt;字符&lt;/strong&gt;是文字的最小的组成单位，其为一种抽象定义(不要与 java 或 c 中的 char 类型混淆，后者为特定计算机语言的数据类型)，取决于语言或是上下文环境，比如’A’, ‘a’为英文中的字符，’纺’,’织’是汉语中的字符(注意绞丝旁并不能称为是一个字符，因为在汉语中，它无法单独成为一个字) 。
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="编码" scheme="http://yoursite.com/tags/%E7%BC%96%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>Windows 10 下安装Tensorflow GPU版</title>
    <link href="http://yoursite.com/2673703756.html"/>
    <id>http://yoursite.com/2673703756.html</id>
    <published>2018-04-14T16:00:00.000Z</published>
    <updated>2019-03-25T09:47:52.598Z</updated>
    
    <content type="html"><![CDATA[<p>之前在自己的windows上安装了tensorflow1.0.1-CPU版，后来想用gpu进行计算，于是安装gpu版。没想到软件之间的依赖关系、版本等导致数种问题，百度谷歌良久才调通程序，特记下曲折的安装过程和一些细节，尽量解释选择软件版本的原因，希望能减轻读者的痛苦。<br><a id="more"></a></p><h2 id="我的环境"><a href="#我的环境" class="headerlink" title="我的环境"></a>我的环境</h2><ul><li><strong>操作系统：Windows 10 64bit</strong></li><li><strong>显卡型号：GeForce GTX 950M</strong></li></ul><h2 id="软件准备"><a href="#软件准备" class="headerlink" title="软件准备"></a>软件准备</h2><ul><li><p><strong>Anaconda3-4.2.0-Windows-x86_64.exe</strong></p><blockquote><p><a href="https://www.continuum.io/" target="_blank">Anaconda</a>是一个用于科学计算的Python发行版，安装后，python以及常用的用于计算的package如numpy、matplotlib、Pillow也都安装好了，而且还能切换不同版本的python，很方便。<br> 安装tensorflow是不必安装Anaconda的，但是你至少要有python环境，而且需要是python3.5.x，因为正式1.0版的tensorflow不支持python2.x版。<br>Anaconda3中内置的python为3.x版本（Anaconda2中内置的python为2.x版本），不过最新的Anaconda内置python为3.6版，为了避免潜在的麻烦，我安装了较新的历史版本（没错，Anaconda可以切换python版本，不过我之前在Anaconda2下安装python3后出现了一些问题，没时间较真了）。</p><p><a href="https://repo.continuum.io/archive/index.html" target="_blank">Anaconda 官网历史版本下载</a></p><p><a href="http://python.jobbole.com/86236/" target="_blank">一篇不错的入门教程</a></p></blockquote></li><li><p><strong>tensorflow_gpu-1.0.1-cp35-cp35m-win_amd64.whl</strong></p><blockquote><p>  <a href="https://github.com/tensorflow/tensorflow" target="_blank">tensorflow</a>在github的提供了以下几个版本：<br></p><ul><li>Linux CPU-only: Python 2 / Python 3.4 / Python 3.5<br></li><li>Linux GPU: Python 2 / Python 3.4 / Python 3.5<br></li><li>Mac CPU-only: Python 2 / Python 3 <br></li><li>Mac GPU: Python 2 / Python 3 <br></li><li>Windows CPU-only: Python 3.5 64-bit<br></li><li><a href="https://ci.tensorflow.org/view/Nightly/job/nightly-win/DEVICE=gpu,OS=windows/lastSuccessfulBuild/artifact/cmake_build/tf_python/dist/tensorflow_gpu-1.0.1-cp35-cp35m-win_amd64.whl" target="_blank">Windows GPU: Python 3.5 64-bit</a><br></li><li>Android: demo APK, native libs</li></ul></blockquote></li><li><p><strong>DirectX SDK</strong></p><blockquote><p><a href="https://www.microsoft.com/en-us/download/details.aspx?id=6812" target="_blank">官网下载</a></p></blockquote></li><li><p><strong>VS2015/2013/2012</strong></p><blockquote><p><strong>安装cuda前必须先安装一款VS</strong>，具体安装哪款，请参照下面对于cuda的介绍。</p></blockquote></li><li><p><strong>cudnn-8.0-windows10-x64-v5.1</strong></p><blockquote><p>针对深度神经网络采用GPU计算的加速库，下载解压后你会得到3个.dll文件。</p><p><a href="https://developer.nvidia.com/cudnn" target="_blank">官网下载（下载需要注册，并且回答一些问题）</a></p></blockquote></li></ul><h2 id="安装-cuda"><a href="#安装-cuda" class="headerlink" title="安装 cuda"></a>安装 cuda</h2><blockquote><p>cuda是一种并行计算平台，可以利用gpu进行并行计算。<br><strong>请注意，tensorflow1.x-gpu版只支持cuda8.x版本</strong>，<a href="https://github.com/tensorflow/tensorflow/issues/8161" target="_blank" rel="noopener">你可以在这里确认这个问题</a></p></blockquote><p>  操作系统对cuda8的支持（常用的系统应该都没问题，即使在cross情况下——32位的系统在64位机器上）:<br></p><table><thead><tr><th style="text-align:center">Operating System</th><th style="text-align:center">Native x86_64</th><th style="text-align:center">Cross (x86_32 on x86_64)</th></tr></thead><tbody><tr><td style="text-align:center">Windows 10</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr><tr><td style="text-align:center">Windows 8.1</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr><tr><td style="text-align:center">Windows 7</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr><tr><td style="text-align:center">Windows Server 2012 R2</td><td style="text-align:center">YES</td><td style="text-align:center">NO</td></tr><tr><td style="text-align:center">Windows Server 2008 R2 DEPRECATED</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr></tbody></table><p>VS对cuda8的支持(<strong>注意cross情况</strong>):</p><table><thead><tr><th style="text-align:left">Compiler IDE</th><th style="text-align:left">Operating System</th><th style="text-align:center">Native x86_64</th><th style="text-align:center">Cross (x86_32 on x86_64)</th></tr></thead><tbody><tr><td style="text-align:left">Visual C++ 14.0</td><td style="text-align:left">Visual Studio 2015</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr><tr><td style="text-align:left">Visual C++ 14.0</td><td style="text-align:left"><strong>Visual Studio Community 2015</strong></td><td style="text-align:center">YES</td><td style="text-align:center"><strong>NO</strong></td></tr><tr><td style="text-align:left">Visual C++ 12.0</td><td style="text-align:left">Visual Studio 2013</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr><tr><td style="text-align:left">Visual C++ 11.0</td><td style="text-align:left">Visual Studio 2012</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr><tr><td style="text-align:left">Visual C++ 10.0 DEPRECATED</td><td style="text-align:left">Visual Studio 2010</td><td style="text-align:center">YES</td><td style="text-align:center">YES</td></tr></tbody></table><p><a href="http://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html#compiling-examples__valid-results-from-sample-cuda-bandwidthtest-program" target="_blank">cuda官网安装教程（这里有上面两张表格）</a></p><blockquote><p>我之前就不幸地安装了唯一一种不支持的情况，安装Visual Studio Community 2015 32bit在我64bit笔记本上，报了一堆错，卸载后安装vs2013后解决问题。<br>到这里你就可以根据自己的情况安装对应的VS了。</p></blockquote><p><a href="https://developer.nvidia.com/cuda-downloads" target="_blank">官网下载</a></p><hr><h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><ul><li><strong>cudnn是必要的</strong><br>我之前参考了一些教程，以为cudnn只是为了提速，并不是必须的，就没有安装，结果出错。在<a href="https://www.tensorflow.org/install/install_windows" target="_blank" rel="noopener">tensorflow官网安装教程</a>中，要求cudnn是必装的，并且要将动态链接库文件添加到环境变量中，我照做后仍报错，后来参照<a href="http://www.jianshu.com/p/c245d46d43f0" target="_blank" rel="noopener">这篇教程</a>将3个.dll文件拷贝到duda安装目录下对应路径下，解决问题。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前在自己的windows上安装了tensorflow1.0.1-CPU版，后来想用gpu进行计算，于是安装gpu版。没想到软件之间的依赖关系、版本等导致数种问题，百度谷歌良久才调通程序，特记下曲折的安装过程和一些细节，尽量解释选择软件版本的原因，希望能减轻读者的痛苦。&lt;br&gt;
    
    </summary>
    
    
      <category term="tensorflow" scheme="http://yoursite.com/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>Hello Blog</title>
    <link href="http://yoursite.com/3393309510.html"/>
    <id>http://yoursite.com/3393309510.html</id>
    <published>2018-04-03T16:00:00.000Z</published>
    <updated>2019-03-25T09:47:52.597Z</updated>
    
    <content type="html"><![CDATA[<p>打算搭建个博客，记录学习经验。<br>想想还有点小激动呢^_^</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;打算搭建个博客，记录学习经验。&lt;br&gt;想想还有点小激动呢^_^&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="随笔" scheme="http://yoursite.com/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
</feed>
